{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105f13a7-64d4-4965-aa8d-fbde40f562dc",
   "metadata": {},
   "source": [
    "- Since time.clock() is no longer supported in python 3.8, clock() has been replaced to perf_counter() in three files of openopt: result.py, runProbSolver.py, ooIter.py\n",
    "- Solver for linear optimization has changed to gurobi in lpsolver.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb72fa5-0ad5-4bab-8621-8ea7eb8e6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from freeflux import Model\n",
    "\n",
    "merged_dict = {\n",
    "    \n",
    "    'mmo_mdh' : ['rxn00843_c0', 'rxn14207_c0'], # 2\n",
    "    'H4MPT_nadh'  : ['rxn07847_c0', 'rxn37236_c0', 'rxn02480_c0', 'rxn02431_c0', 'rxn07849_c0'], # 5\n",
    "    'H4MPT_nadph' : ['rxn07847_c0', 'rxn07848_c0', 'rxn02480_c0', 'rxn02431_c0', 'rxn07849_c0'], # 5\n",
    "    'H4F_reductive' : ['rxn01211_c0', 'rxn00907_c0'], # 2\n",
    "    'ser_to_pg_nadh' : ['rxn00424_c0', 'rxn01011_c0', 'rxn01102_c0'], # 3\n",
    "    'ser_to_pg_nadph' : ['rxn00424_c0', 'rxn01013_c0', 'rxn01102_c0'], # 3\n",
    "    'pg_to_pep' : ['rxn01106_c0', 'rxn00459_c0'], # 2\n",
    "    'mal_to_glx_accoa' : ['rxn00934_c0', 'rxn00331_c0'], # 2\n",
    "    'EMC_nadh' : ['rxn00178_c0', 'rxn01451_c0', 'rxn02345_c0', 'rxn02167_c0', 'rxn16150_c0', 'rxn16825_c0', \n",
    "                  'rxn16151_c0', 'rxn25269_c0', 'rxn03440_c0', 'rxn00682_c0', 'rxn01355_c0', 'rxn01996_c0', 'rxn00602_c0'], # 13\n",
    "    'EMC_nadph' : ['rxn00178_c0', 'rxn01453_c0', 'rxn02345_c0', 'rxn02167_c0', 'rxn16150_c0', 'rxn16825_c0', \n",
    "                  'rxn16151_c0', 'rxn25269_c0', 'rxn03440_c0', 'rxn00682_c0', 'rxn01355_c0', 'rxn01996_c0', 'rxn00602_c0'], # 13\n",
    "    'cit_to_akg' : ['rxn00974_c0', 'rxn01388_c0', 'rxn00198_c0'], # 3\n",
    "    'pg_to_gap' : ['rxn01100_c0', 'rxn00781_c0'], # 2\n",
    "    'f6p_to_gap_dhap' : ['rxn00786_c0', 'rxn00549_c0', 'rxn00747_c0'], # 3\n",
    "    'x5p_r5p' : ['rxn00777_c0', 'rxn01116_c0'], # 2\n",
    "    'e4p_dhap_to_s7p' : ['rxn01334_c0', 'rxn01343_c0'] # 2\n",
    "# total \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "DILUTION_FROM = [\n",
    "    'cpd00011u', # co2\n",
    "    'cpd00023u', # glutamate\n",
    "    'cpd00024u' # akg\n",
    "    # 'cpd00041u' # aspartate\n",
    "    # 'cpd00036u', # succinate\n",
    "    # 'cpd00072u', # f6p\n",
    "    # 'cpd00101u', # r5p\n",
    "    # 'cpd00106u', # fumarate\n",
    "    # 'cpd00130u', # malate\n",
    "    # 'cpd00137u' # citrate\n",
    "    # 'cpd00169u', # phosphoglycerate\n",
    "    # 'cpd00236u', # e4p\n",
    "    # 'cpd00238u'  # s7p\n",
    "]\n",
    "\n",
    "\n",
    "# estimate fluxes at steady state\n",
    "def steady_state_fitting():\n",
    "\n",
    "    ob3b = Model('OB3b_wt')\n",
    "    ob3b.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with ob3b.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['1'], \n",
    "            percentage = [0.25], \n",
    "            purity = [0.99]\n",
    "        )\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "        \n",
    "        # set upper and lower bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-100, 100]) \n",
    "        \n",
    "        # solve the fluxes\n",
    "        fit.prepare(\n",
    "            dilution_from = DILUTION_FROM, \n",
    "            n_jobs = 30\n",
    "        )\n",
    "        while True:\n",
    "            res = fit.solve(solver = 'ralg', max_iters = 1000)\n",
    "            if res.optimization_successful:\n",
    "            # if res.opt_objective < 2000:\n",
    "                break\n",
    "    \n",
    "    # save the results\n",
    "    pd.Series(res.opt_net_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_net_fluxes.xlsx'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_total_fluxes.xlsx'\n",
    "    )\n",
    "\n",
    "    net_cis = res.estimate_confidence_intervals(\n",
    "        which = 'net', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    total_cis = res.estimate_confidence_intervals(\n",
    "        which = 'total', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(net_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/netflux_le_CIs.xlsx'\n",
    "    )\n",
    "    pd.DataFrame(total_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/totalflux_le_CIs.xlsx'\n",
    "    )\n",
    "\n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = OUT_DIR)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_contribMat.xlsx'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_contribMat.xlsx'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_senMat.xlsx'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_senMat.xlsx'\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({'opt_resids': res.opt_resids})\n",
    "    df.to_csv(OUT_DIR + \"/opt_resids.csv\", index=False)\n",
    "\n",
    "    sim_flux = pd.Series(res.opt_net_fluxes)\n",
    "    sim_flux.to_csv(\n",
    "    OUT_DIR+'/estimated_net_fluxes.csv'\n",
    "    )\n",
    "    \n",
    "    flux = {}\n",
    "    merged_rxn = list(merged_dict.keys())\n",
    "    for i in range(len(sim_flux)):\n",
    "        rxn_id = sim_flux.index[i]\n",
    "        rxn_flux = sim_flux.values[i]\n",
    "        \n",
    "        if rxn_id in merged_rxn:\n",
    "            rxns = merged_dict[rxn_id]\n",
    "            for r in rxns:\n",
    "                if r not in flux:\n",
    "                    flux[r] = rxn_flux\n",
    "                else:\n",
    "                    flux[r] += rxn_flux\n",
    "        else:\n",
    "            flux[rxn_id] = rxn_flux\n",
    "    flux_pd_series = pd.Series(flux)\n",
    "    flux_pd_series.to_csv(OUT_DIR + 'net_fluxes.csv')\n",
    "    \n",
    "    ref = flux['rxn00692_c0']\n",
    "    norm_flux = pd.Series(\n",
    "        list(flux.values())/ref, name = 'fluxes', index = list(flux.keys())\n",
    "    )\n",
    "    norm_flux.to_csv(OUT_DIR + 'net_normalized_fluxes.csv')\n",
    "\n",
    "    \n",
    "    data_list = []\n",
    "    for key in res.simulated_MDVs.keys():\n",
    "        for i in range(len(res.simulated_MDVs[key])):\n",
    "            data_list.append([key, f\"M{i}\", \"Simulated\", res.simulated_MDVs[key][i], None])  # No SD for simulated\n",
    "            data_list.append([key, f\"M{i}\", \"Measured\", res.measured_MDVs[key][0][i], res.measured_MDVs[key][1][i]])  # With SD\n",
    "    \n",
    "    df = pd.DataFrame(data_list, columns=[\"Metabolite\", \"Isotopomer\", \"Type\", \"Value\", \"SD\"])\n",
    "    df.to_csv(OUT_DIR + \"/MDVs_data.csv\", index=False)\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842b6da-58ac-463d-b1f3-6f78a4840aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM_OB3b/multi_omics/metabolomic/13c_flux_simulation/wt_simulation/'\n",
    "MODEL_FILE       = base_dir + '0_wt_input_data/WT_10CU_MODEL.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_wt_input_data/WT_10CU_MDV.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_wt_input_data/WT_10CU_FLUX.xlsx'\n",
    "OUT_DIR          = base_dir\n",
    "wt_mfa           = steady_state_fitting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df12f4-5b37-4416-b7f2-4955d0b7a78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM_OB3b/multi_omics/metabolomic/13c_flux_simulation/mut_1_simulation/'\n",
    "MODEL_FILE       = base_dir + '0_mut_1_input_data/MUT_1_10CU_MODEL.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_mut_1_input_data/MUT_1_10CU_MDV.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_mut_1_input_data/MUT_1_10CU_FLUX.xlsx'\n",
    "OUT_DIR          = base_dir\n",
    "mut_1_mfa        = steady_state_fitting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ac643-3fe8-456d-9eac-6e5f70fe6b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM_OB3b/multi_omics/metabolomic/13c_flux_simulation/mut_2_simulation/'\n",
    "MODEL_FILE       = base_dir + '0_mut_2_input_data/MUT_2_10CU_MODEL.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_mut_2_input_data/MUT_2_10CU_MDV.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_mut_2_input_data/MUT_2_10CU_FLUX.xlsx'\n",
    "OUT_DIR          = base_dir\n",
    "mut_2_mfa        = steady_state_fitting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f554f-2b6b-4dff-ab82-eb0663fac033",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "import freeflux as ff\n",
    "# import cobra\n",
    "\n",
    "# cobra_config = cobra.Configuration()\n",
    "# cobra_config.solver = \"gurobi\"\n",
    "\n",
    "# ModelDir = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6567c454-a9d2-4e34-9742-9d06069ca4c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "md = cobra.io.read_sbml_model(ModelDir + \"GEM_ADVE_v13d_Gvalentino.xml\")\n",
    "md.reactions.EX_cpd00007_e0.bounds = (-23,0)\n",
    "md.reactions.EX_cpd01024_e0.bounds = (-1000,0)\n",
    "# md.reactions.bio1_biomass.bounds = (0.09,0.11)\n",
    "\n",
    "for r in md.reactions:\n",
    "    if r.lower_bound < 0 and r.upper_bound == 0:\n",
    "\n",
    "        # If the reaction only goes in the reverse direction, flip the reaction direction\n",
    "        r.lower_bound, r.upper_bound = r.upper_bound, -r.lower_bound\n",
    "        for met, coeff in r.metabolites.items():\n",
    "            r.add_metabolites({met: -2 * coeff})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63784b-5100-4a3d-900b-3a4833151927",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a dictionary with key = cobra Metabolite, and value = ff Metabolite\n",
    "\n",
    "met_dict = {}\n",
    "for met in md.metabolites:\n",
    "    # met_dict[met.id] = ff.Metabolite(id=met.id)\n",
    "    met_dict[met] = ff.Metabolite(id=met.id)\n",
    "print('Cobra Model metabolites num = ', len(md.metabolites))\n",
    "print('Freeflux Model metabolites num = ', len(met_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cbf09-ba57-416f-9499-c2c114e44772",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of ff Reactions\n",
    "\n",
    "ff_md = ff.Model('sMMO_ff_model')\n",
    "rxn_list = []\n",
    "\n",
    "for rxn in md.reactions:\n",
    "\n",
    "    if rxn.lower_bound * rxn.upper_bound < 0:\n",
    "        ff_rxn = ff.Reaction(id=rxn.id, reversible = True)\n",
    "    else:\n",
    "        ff_rxn = ff.Reaction(id=rxn.id, reversible = False)\n",
    "\n",
    "\n",
    "    for met,coeff in rxn.metabolites.items():\n",
    "        if coeff < 0:\n",
    "            ff_rxn.add_substrates(substrates = met_dict[met], stoichiometry = abs(coeff))\n",
    "        elif coeff > 0:\n",
    "            ff_rxn.add_products(products= met_dict[met], stoichiometry = abs(coeff))\n",
    "\n",
    "    rxn_list.append(ff_rxn)\n",
    "    ff_md.add_reactions(reactions=ff_rxn)\n",
    "    # print(ff_rxn)\n",
    "\n",
    "### Five metabolites have no reactions:\n",
    "### cpd00074_c0, cpd00649_c0, cpd00792_c0, cpd11609_c0, cpd11610_c0\n",
    "print(len(md.metabolites), ff_md.n_metabolites)\n",
    "print(len(md.reactions), ff_md.n_reactions)\n",
    "\n",
    "# for met in md.metabolites:\n",
    "#     if met.id not in ff_md.metabolites:\n",
    "#         print(met.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa1d9c-6292-467d-b8ab-b9f9e0ce42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ff_md.optimizer() as opt:\n",
    "\n",
    "    for rxn in list(ff_md.reactions_info.keys()):\n",
    "        rxn_lb = md.reactions.get_by_id(rxn).lower_bound\n",
    "        rxn_ub = md.reactions.get_by_id(rxn).upper_bound\n",
    "        opt.set_flux_bounds(fluxid = rxn, bounds = [rxn_lb, rxn_ub])\n",
    "    # opt.prepare()\n",
    "    res = opt.optimize(objective = {'bio1_biomass': 1}, direction='max')\n",
    "\n",
    "print('objective:', res.opt_objective)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad421bb-5ee3-4e1c-9be6-f218e0d92ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('objective:', res.opt_objective)\n",
    "print(res.opt_fluxes['EX_cpd00007_e0'])\n",
    "print(res.opt_fluxes['EX_cpd01024_e0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571230d-7cf9-47a8-87a4-6405c684e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_sol = md.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23dd88-13b0-47c0-9eb0-878880d4145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_sol.fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01c9f1-a4a9-4d92-8c3e-6d0d9b5c0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_sol.fluxes.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca72fc-3db9-4681-80b2-98d7d08a1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.reactions.rxn00251_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b10075-59dc-433b-af27-7823927ceebb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from os import makedirs\n",
    "import pandas as pd\n",
    "import freeflux as ff\n",
    "import cobra\n",
    "\n",
    "cobra_config = cobra.Configuration()\n",
    "cobra_config.solver = \"gurobi\"\n",
    "\n",
    "ModelDir = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fe5e3-5d06-4ad8-903c-aeeffa79d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_reaction(rxn_list):\n",
    "    for r in rxn_list:\n",
    "        r.lower_bound, r.upper_bound = -r.upper_bound, -r.lower_bound\n",
    "        for met, coeff in r.metabolites.items():\n",
    "            r.add_metabolites({met: -2 * coeff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2d7cd-9509-442f-98ef-f55a8c54e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = cobra.io.read_sbml_model(ModelDir + \"ff_model.xml\")\n",
    "flip_reaction(\n",
    "    [md.reactions.rxn00182_c0, \n",
    "     md.reactions.rxn00184_c0,\n",
    "     md.reactions.rxn00248_c0\n",
    "    ]\n",
    ")\n",
    "\n",
    "for r in list(md.reactions):\n",
    "    if r.lower_bound < 0 and r.upper_bound == 0:\n",
    "        r.lower_bound, r.upper_bound = r.upper_bound, -r.lower_bound\n",
    "        for met, coeff in r.metabolites.items():\n",
    "            r.add_metabolites({met: -2 * coeff})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b7c04-ce7c-4d2e-aec6-a642464ddeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Core metabolic reactoin list\n",
    "\n",
    "# Methane oxidation to CO2\n",
    "ch4_oxidation = [\n",
    "    '00843', '14207', '07847', '07848', '37236', \n",
    "    '02480', '02431', '07849', '00371', '00690', \n",
    "    '01211', '00907', '12217'\n",
    "]\n",
    "\n",
    "central_metabolic_cycles = [\n",
    "    '00692', '00424', '01011', '01013', '01102', \n",
    "    '01106', '00459', '00251', '00248', '00934', \n",
    "    '00331', '00990', '00178', '01453', '01451', \n",
    "    '02345', '02167', '16150', '16825', '16151', \n",
    "    '25269', '03440', '00682', '01355', '01996', \n",
    "    '00602', '00256', '00974', '01388', '00198', \n",
    "    '08094', '00285', '09272', '00799', '04954'\n",
    "]\n",
    "\n",
    "etcetera = [\n",
    "    '00148', '00154', '00182', '00184', '00085', '00187',\n",
    "    '00175', '00225', '00173' # AcCoa, Ac cycles\n",
    "]\n",
    "\n",
    "glycppp = [\n",
    "    '01100', '00781', '00786', '00747', '00549',\n",
    "    '00558', '00777', '01116'\n",
    "]\n",
    "\n",
    "cc_rxn_list = ch4_oxidation + central_metabolic_cycles + etcetera + glycppp\n",
    "\n",
    "for i, rxn in enumerate(cc_rxn_list):\n",
    "    rxn_id = 'rxn' + rxn + '_c0'\n",
    "    cc_rxn_list[i] = rxn_id\n",
    "# cc_rxn_list\n",
    "md_check_dict = {}\n",
    "for rxn in cc_rxn_list:\n",
    "    md_check_dict[rxn] = 1\n",
    "\n",
    "md_check = pd.Series(md_check_dict, name = 'fluxes')\n",
    "md_check.to_csv('rxn_check.csv')\n",
    "\n",
    "# list of non-carbon metabolites that should be remained in model for flux balance\n",
    "# ATP, O2, NH4, NO3, NADH, NADPH, AcCoA, SucCoA, MalCoA, me/ml/f-thf/h4mpt\n",
    "required_met = [\n",
    "    'cpd00002_c0', 'cpd00007_c0', 'cpd00013_c0', 'cpd00209_c0', 'cpd00004_c0','cpd00005_c0'\n",
    "]\n",
    "remove_met = [\n",
    "    'cpd00003_c0', 'cpd00006_c0', # NAD, NADP\n",
    "    'cpd00008_c0', # ADP\n",
    "    'cpd00010_c0', # CoA\n",
    "    'cpd00109_c0', 'cpd00110_c0', # cytochrome red/ox\n",
    "    'cpd15560_c0', 'cpd15561_c0', # Ubi red/ox\n",
    "    'cpd00895_c0', 'cpd00087_c0', 'cpd00643_c0' # H4MPT, THF, Mefur\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ea062-b031-42ef-9b4d-f2493aa986de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(md.reactions.get_by_id('rxn02431_c0').reaction)\n",
    "# for rxn in cc_rxn_list:\n",
    "#     r = md.reactions.get_by_id(rxn)\n",
    "#     if r.lower_bound < 0 and r.upper_bound == 0:            \n",
    "#         # If the reaction only goes in the reverse direction, flip the reaction direction\n",
    "#         r.lower_bound, r.upper_bound = r.upper_bound, -r.lower_bound\n",
    "#         for met, coeff in r.metabolites.items():\n",
    "#             r.add_metabolites({met: -2 * coeff})\n",
    "# # print(md.reactions.get_by_id('rxn02431_c0').reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d30c0-0e98-4b0f-8694-58f2f8ad9726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rxn in cc_rxn_list:\n",
    "\n",
    "    # print(md.reactions.get_by_id(rxn).name)\n",
    "    # print(md.reactions.get_by_id(rxn).id)\n",
    "    # print(md.reactions.get_by_id(rxn).reaction)\n",
    "\n",
    "    for met, coeff in md.reactions.get_by_id(rxn).metabolites.items():\n",
    "        \n",
    "        # if len(met.formula) >= 10 and met.id not in required_met:\n",
    "        #     md.reactions.get_by_id(rxn).add_metabolites({met:-coeff})\n",
    "            \n",
    "        if 'C' not in met.formula and met.id not in required_met:\n",
    "            md.reactions.get_by_id(rxn).add_metabolites({met:-coeff})\n",
    "\n",
    "        elif met.id in remove_met:\n",
    "            md.reactions.get_by_id(rxn).add_metabolites({met:-coeff})\n",
    "    # print(md.reactions.get_by_id(rxn).reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379253f-13f9-42a6-a0a4-84be6cc538aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### create dict for ff reaction dataframe\n",
    "cc_rxn_dict = {}\n",
    "\n",
    "### Col_1: reaction_ID\n",
    "cc_rxn_dict['reaction_ID'] = [md.reactions.get_by_id(rxn).id for rxn in cc_rxn_list]\n",
    "\n",
    "c_adjust_dict = {'-coa': 21, \n",
    "                 'h4mpt': 30,\n",
    "                 'tetrahydromethanopterin': 30,\n",
    "                 'methanofuran': 34,\n",
    "                 'tetrahydrofolate': 19}\n",
    "### Col_2: substrate_IDs(atom)\n",
    "### Col_3: product_IDs(atom)\n",
    "carbon_label = 'abcdefghijklmnopqrstuvwxyz'\n",
    "# one_carbon_list = ['methanopterin', 'h4mpt', 'methanofuran', 'tetrahydrofolate']\n",
    "# two_carbon_list = ['acetyl-coa']\n",
    "# four_carbon_list = ['acetoacetyl-coa', 'hydroxybutanoyl-coa', 'hydroxybutyryl-coA', 'crotonyl-coa']\n",
    "# five_carbon_list = ['ethylmalonyl-coa', 'methylsuccinyl-coa', 'mesaconyl-coa', 'methylmalyl-coa',\n",
    "#                     '']\n",
    "subs_list = []\n",
    "prod_list = []\n",
    "\n",
    "\n",
    "for rxn in cc_rxn_list:\n",
    "   \n",
    "    rxn_subs = []\n",
    "    rxn_prod = []\n",
    "\n",
    "    carbon_label_subs = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    carbon_label_prod = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    for met, coeff in md.reactions.get_by_id(rxn).metabolites.items():\n",
    "      \n",
    "        met_formula = met.formula\n",
    "        \n",
    "        met_unpack = [s for s in met_formula]\n",
    "        met_re = re.split('(\\d+)',met_formula)\n",
    "        \n",
    "        try:\n",
    "            c = met_unpack.index('C') + 1\n",
    "        except:\n",
    "            c = 0\n",
    "       \n",
    "        if c != 0: \n",
    "            try:\n",
    "                c_num_ind = met_re.index('C')+1\n",
    "                c_num = int(met_re[c_num_ind])\n",
    "            except:\n",
    "                c_num = 1\n",
    "        else:\n",
    "            c_num = 0 \n",
    "        \n",
    "        if '_c0' in met.name:\n",
    "            c_check = met.name[:-3]\n",
    "        elif '_e0' in met.name:\n",
    "            c_check = met.name[:-3]\n",
    "        else:\n",
    "            c_check = met.name\n",
    "        \n",
    "        for c in list(c_adjust_dict.keys()):\n",
    "            if c in c_check.lower():\n",
    "                c_num = c_num - c_adjust_dict[c]\n",
    "                \n",
    "        if c_num > 8:\n",
    "            c_num = 0            \n",
    "        \n",
    "        \n",
    "        if abs(coeff) != 1:\n",
    "            met_id = str(abs(coeff))+met.id[0:-3]\n",
    "        else:\n",
    "            met_id = met.id[0:-3]\n",
    "\n",
    "        \n",
    "        \n",
    "        if c_num != 0:\n",
    "            if coeff < 0:\n",
    "                rxn_subs.append(met_id+'('+carbon_label_subs[:c_num]+')')\n",
    "                carbon_label_subs = carbon_label_subs[c_num:]\n",
    "            elif coeff > 0:\n",
    "                rxn_prod.append(met_id+'('+carbon_label_prod[:c_num]+')')\n",
    "                carbon_label_prod = carbon_label_prod[c_num:]\n",
    "        else:\n",
    "            if coeff < 0:\n",
    "                rxn_subs.append(met_id)\n",
    "            elif coeff > 0:\n",
    "                rxn_prod.append(met_id)        \n",
    "        \n",
    "        # print(rxn, c_check, c_num, met_id)\n",
    "        # print(rxn_subs)\n",
    "        # print(rxn_prod)\n",
    "    \n",
    "    subs_list.append('+'.join(rxn_subs))\n",
    "    prod_list.append('+'.join(rxn_prod))\n",
    "\n",
    "cc_rxn_dict['substrate_IDs(atom)'] = subs_list\n",
    "cc_rxn_dict['product_IDs(atom)'] = prod_list\n",
    "\n",
    "\n",
    "### Col_4: reversibility\n",
    "reversibility = []\n",
    "for rxn in cc_rxn_list:\n",
    "\n",
    "    lb = md.reactions.get_by_id(rxn).lower_bound\n",
    "    ub = md.reactions.get_by_id(rxn).upper_bound\n",
    "\n",
    "    if lb >= 0 and ub > 0 :\n",
    "        reversibility.append('0')\n",
    "    elif lb < 0 and ub > 0 :\n",
    "        reversibility.append('1')\n",
    "    elif lb < 0 and ub <= 0 :\n",
    "        reversibility.append('0')\n",
    "\n",
    "cc_rxn_dict['reversibility'] = reversibility        \n",
    "\n",
    "cc_rxn_df = pd.DataFrame(cc_rxn_dict)\n",
    "# cc_rxn_df.to_csv('cc_rxn_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8be0cc-0cf7-4895-9bc3-128ded449a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa_rxn_dict = {}\n",
    "## Check if cpd00032 (cpd00032) required for biomass\n",
    "## SO4 (cpd00048) exchange required\n",
    "\n",
    "aa_rxn_dict['reaction_ID'] = [\n",
    "# 'gdh',\n",
    "# 'gs',\n",
    "'pro',\n",
    "'arg',\n",
    "'asp',\n",
    "'asn',\n",
    "'ala',\n",
    "'ser',\n",
    "# 'gly1',\n",
    "# 'gldc',\n",
    "# 'gly2',\n",
    "'cys',\n",
    "'lys1',\n",
    "'lys2',\n",
    "'thr',\n",
    "'met',\n",
    "'val',\n",
    "'leu',\n",
    "'ile',\n",
    "'phe',\n",
    "'tyr',\n",
    "'trp',\n",
    "'his',\n",
    "\n",
    "'biom'\n",
    "]\n",
    "\n",
    "aa_rxn_dict['substrate_IDs(atom)'] = [\n",
    "# 'cpd00024(abcde)+cpd00005+cpd00013'\n",
    "# 'cpd00023(abcde)+cpd00002+cpd00013'\n",
    "'cpd00023(abcde)+cpd00002+2cpd00005',\n",
    "'cpd00023(abcde)+cpd00011(f)+cpd00053(ghijk)+cpd00041(lmno)+cpd00022(pq)+5cpd00002+cpd00005',\n",
    "'cpd00032(abcd)+cpd00023(efghi)',\n",
    "'cpd00041(abcd)+2cpd00002+cpd00013',\n",
    "'cpd00020(abc)+cpd00004+cpd00013',\n",
    "'cpd00169(abc)+cpd00023(defgh)',\n",
    "# 'cpd00054(abc)'\n",
    "# 'cpd00033(ab)'\n",
    "# 'cpd00161(abcd)'\n",
    "'cpd00054(abc)+cpd00022(de)+3cpd00002+4cpd00005+cpd00048',\n",
    "'cpd00041(abcd)+cpd00020(efg)+cpd00023(hijkl)+cpd00078(mnop)+cpd00002+2cpd00005',\n",
    "'cpd00516(abcdefg)',\n",
    "'cpd00041(abcd)+2cpd00002+2cpd00005',\n",
    "'cpd00041(abcd)+cpd00345(e)+cpd00084(fgh)+cpd00078(ijkl)+cpd00002+2cpd00005',\n",
    "'cpd00020(abc)+cpd00020(def)+cpd00023(ghijk)+cpd00005',\n",
    "'cpd00022(ab)+cpd00020(cde)+cpd00020(fgh)+cpd00023(ijklm)+cpd00005',\n",
    "'cpd00161(abcd)+cpd00020(efg)+cpd00023(hijkl)+cpd00005',\n",
    "'cpd00061(abc)+cpd00061(def)+cpd00236(ghij)+cpd00023(klmno)+cpd00002+cpd00005',\n",
    "'cpd00061(abc)+cpd00061(def)+cpd00236(ghij)+cpd00023(klmno)+cpd00002+cpd00005',\n",
    "'cpd00054(abc)+cpd00101(defgh)+cpd00061(ijk)+cpd00236(lmno)+cpd00061(pqr)+cpd00053(stuvw)+3cpd00002+cpd00005',\n",
    "'cpd00101(abcde)+cpd00201(f)+cpd00053(ghijk)+cpd00041(lmno)+5cpd00002',\n",
    "\n",
    "'0.488cpd00035+0.281cpd00051+0.229cpd00132+0.229cpd00041+0.087cpd00084+0.250cpd00023+0.250cpd00053+0.582cpd00033+0.090cpd00119+0.276cpd00322+0.428cpd00107+0.326cpd00039+0.146cpd00060+0.176cpd00066+0.210cpd00129+0.205cpd00054+0.241cpd00161+0.054cpd00065+0.131cpd00069+0.402cpd00156+0.205cpd00079+0.071cpd00072+0.754cpd00101+0.129cpd00102+0.619cpd00169+0.051cpd00061+0.083cpd00020+2.510cpd00022+0.087cpd00024+0.340cpd00032+0.443cpd00125+55cpd00002+5.363cpd00005'\n",
    "]\n",
    "\n",
    "aa_rxn_dict['product_IDs(atom)'] = [\n",
    "# 'cpd00023(abcde)',\n",
    "# 'cpd00053(abcde)',\n",
    "'cpd00129(abcde)',\n",
    "'cpd00051(abcdef)+cpd00024(ghijk)+cpd00106(lmno)+cpd00029(pq)',\n",
    "'cpd00041(abcd)+cpd00024(efghi)',\n",
    "'cpd00132(abcd)',\n",
    "'cpd00035(abc)',\n",
    "'cpd00054(abc)+cpd00024(defgh)+cpd00004',\n",
    "# 'cpd00033(ab)+cpd00125(c)',\n",
    "# 'cpd00011(a)+cpd00125(b)+cpd00004+cpd00013',\n",
    "# 'cpd00033(ab)+cpd00022(cd)+cpd00004',\n",
    "'cpd00084(abc)+cpd00029(de)',\n",
    "'cpd00516(abcdgfe)+cpd00024(hijkl)+cpd00036(mnop,ponm)',\n",
    "'cpd00039(abcdef)+cpd00011(g)',\n",
    "'cpd00161(abcd)',\n",
    "'cpd00060(abcde)+cpd00020(fgh)+cpd00036(ijkl,lkji)+cpd00013',\n",
    "'cpd00156(abcef)+cpd00011(d)+cpd00024(ghijk)',\n",
    "'cpd00107(abdghe)+cpd00011(c)+cpd00011(f)+cpd00024(ijklm)+cpd00004',\n",
    "'cpd00322(abfcdg)+cpd00011(e)+cpd00024(hijkl)+cpd00013',\n",
    "'cpd00066(abcefghij)+cpd00011(d)+cpd00024(klmno)',\n",
    "'cpd00069(abcefghij)+cpd00011(d)+cpd00024(klmno)+cpd00004',\n",
    "'cpd00065(abcedklmnoj)+cpd00011(i)+cpd00102(fgh)+cpd00020(pqr)+cpd00023(stuvw)',\n",
    "'cpd00119(edcbaf)+cpd00024(ghijk)+cpd00106(lmno)+2cpd00004',\n",
    "\n",
    "'39.68Biomass+1.455NADH'\n",
    "]\n",
    "\n",
    "aa_rxn_dict['reversibility'] = [\n",
    "# '0',\n",
    "# '0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "# '1',\n",
    "# '1',\n",
    "# '0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0'\n",
    "]\n",
    "\n",
    "aa_rxn_df = pd.DataFrame(aa_rxn_dict)\n",
    "# aa_rxn_df\n",
    "# aa_rxn_df.to_csv('aa_rxn_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8e402-d4f7-4a78-9e33-af91493240b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_rxn_dict = {}\n",
    "\n",
    "ex_rxn_dict['reaction_ID'] = [\n",
    "'atps1',\n",
    "'atps2',\n",
    "'nnt',\n",
    "'atpm',\n",
    "'ch4in',\n",
    "'co2out',\t\n",
    "'o2in',\t\n",
    "# 'acout',\t\n",
    "'nh4in',\t\n",
    "'so4in'\n",
    "]\n",
    "\n",
    "ex_rxn_dict['substrate_IDs(atom)'] = [\n",
    "'cpd00004+0.5cpd00007',\n",
    "'cpd00982+0.5cpd00007',\n",
    "'cpd00004',\n",
    "'cpd00002',\n",
    "'cpd01024.ex(a)',\n",
    "'cpd00011(a)',\n",
    "'cpd00007.ex',\n",
    "# 'Ac(ab)',\n",
    "'cpd00209.ex+cpd00005',\n",
    "'cpd00048.ex'\n",
    "]\n",
    "\n",
    "ex_rxn_dict['product_IDs(atom)'] = [\n",
    "'2cpd00002',\n",
    "'cpd00002',\n",
    "'cpd00005',\n",
    "'cpd00002.ex',\n",
    "'cpd01024(a)',\n",
    "'cpd00011.ex(a)',\n",
    "'cpd00007',\n",
    "# 'Ac.ex(ab)',\n",
    "'cpd00013',\n",
    "'cpd00048'\n",
    "]\n",
    "\n",
    "ex_rxn_dict['reversibility'] = [\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "'0',\n",
    "# '0',\n",
    "'0',\n",
    "'0'\n",
    "]\n",
    "\n",
    "ex_rxn_df = pd.DataFrame(ex_rxn_dict)\n",
    "    \n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0183a1-ad38-427e-8c8d-52929012ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_ta_rxn_dict = {}\n",
    "\n",
    "tk_ta_rxn_dict['reaction_ID'] = [\n",
    "'tkt1',\n",
    "'tkt2',\t\n",
    "'tkt3',\t\n",
    "'tal1',\t\n",
    "'tal2'\t\n",
    "]\n",
    "\n",
    "tk_ta_rxn_dict['substrate_IDs(atom)'] = [\n",
    "'cpd00198(abcde)',\t\n",
    "'cpd00072(abcdef)',\t\n",
    "'cpd00238(abcdefg)',\t\n",
    "'cpd00072(abcdef)',\t\n",
    "'cpd00238(abcdefg)'\t\n",
    "]\n",
    "\n",
    "tk_ta_rxn_dict['product_IDs(atom)'] = [\n",
    "'TK(ab)+cpd00102(cde)',\n",
    "'TK(ab)+cpd00236(cdef)',\n",
    "'TK(ab)+cpd00101(cdefg)',\n",
    "'TA(abc)+cpd00102(def)',\n",
    "'TA(abc)+cpd00236(defg)'\n",
    "]\n",
    "\n",
    "tk_ta_rxn_dict['reversibility'] = [\n",
    "'1',\n",
    "'1',\n",
    "'1',\n",
    "'1',\n",
    "'1'\n",
    "]\n",
    "\n",
    "tk_ta_rxn_df = pd.DataFrame(tk_ta_rxn_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10868ef7-84a8-4c69-926e-49406e622623",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_rxn_df = pd.concat(\n",
    "    [cc_rxn_df, aa_rxn_df, ex_rxn_df, tk_ta_rxn_df], \n",
    "    axis=0,ignore_index = True\n",
    ")\n",
    "\n",
    "ff_rxn_df\n",
    "ff_rxn_df.to_csv('ff_rxn_df.csv')\n",
    "\n",
    "## Fix rxn09272: add FADH (cpd00982) in products\n",
    "## Fix rxn01355: change to carbonate (cpd00242) to carbon dioxide (cpd00011)\n",
    "## Fix rxn00085: change carbon label at substrate cpd00053(fghij) to (abcde)\n",
    "\n",
    "## rxn00178: substrate cpd00279(abcd) changed to cpd00279(abab)\n",
    "\n",
    "## Delete: \n",
    "# 'nnt'\n",
    "# 'rxm00990_c0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113e1f8-c9bf-4996-882f-cc66a3d7a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test FBA with ff_rxn_df\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_3/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "\n",
    "ff_md = ff.Model('ff_model_test')\n",
    "ff_md.read_from_file(MODEL_FILE)\n",
    "with ff_md.optimizer() as opt:\n",
    "    opt.set_flux_bounds('all', bounds = [-100, 100])\n",
    "    # opt.set_flux_bounds('ch4in', bounds = [13.5, 15])\n",
    "    opt.set_flux_bounds('o2in', bounds = [21.2, 21.2])\n",
    "    opt.set_flux_bounds('atpm', bounds = [4.21, 4.21])\n",
    "    # opt.set_flux_bounds('pyrin', bounds = [0, 2])\n",
    "\n",
    "    # opt.set_flux_bounds('o2in', bounds = [23, 23])\n",
    "\n",
    "    # opt.set_flux_bounds('rxn07847_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn07848_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn37236_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn02480_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn02431_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn07849_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn00371_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn00248_c0', bounds = [-100, 0])\n",
    "\n",
    "    # opt.set_flux_bounds('rxn00182_c0', bounds = [0, 0])\n",
    "    # opt.set_flux_bounds('rxn00184_c0', bounds = [0, 0])\n",
    "    # opt.set_flux_bounds('atps2', bounds = [0, 1])\n",
    "    # opt.set_flux_bounds('biom', bounds = [0.10, 0.10])\n",
    "    \n",
    "    opt.prepare()\n",
    "    res = opt.optimize(objective = {'biom': 1})\n",
    "    # res = opt.optimize(objective = {'o2in': 1})\n",
    "\n",
    "fluxes_pd_series = pd.Series(\n",
    "    [res.opt_fluxes[rxn] for rxn in ff_md.reactions], name = 'fluxes', index = ff_md.reactions\n",
    ")\n",
    "fluxes_pd_series.to_excel(base_dir + '0_data/WT_FBA_ref_TEST.xlsx')\n",
    "\n",
    "# print('objective:  ',res.opt_objective)\n",
    "# print('growth:     ',res.opt_fluxes['biom'])\n",
    "# print('methane:    ',res.opt_fluxes['ch4in'])\n",
    "# print('oxygen:     ',res.opt_fluxes['o2in'])\n",
    "# print('atpase_1:   ',res.opt_fluxes['atps1'])\n",
    "# print('atpase_2:   ',res.opt_fluxes['atps2'])\n",
    "# print('acetate_out:',res.opt_fluxes['acout'])\n",
    "\n",
    "# print('pyruvate_in:',res.opt_fluxes['pyrin'])\n",
    "# print('citrate_out:',res.opt_fluxes['citout'])\n",
    "# print('succ_out:   ',res.opt_fluxes['succout'])\n",
    "# print('fum_out:    ',res.opt_fluxes['fumout'])\n",
    "\n",
    "# print('formate_out:',res.opt_fluxes['forout'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25315c1-fa23-4f8c-8833-85a490cafe4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_1/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "results_fit_1 = []\n",
    "obj_fit_1     = []\n",
    "for i in range(11, 21):\n",
    "\n",
    "    # make directory\n",
    "    result_dir = base_dir + str(i)\n",
    "    os.mkdir(result_dir)\n",
    "    \n",
    "    model = ff.Model('wt_10cu')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        \n",
    "        # specify the lableing strategy, use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "\n",
    "        # set bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "        fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('atpm', bounds = [20, 30])\n",
    "        fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "\n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "\n",
    "        # slove the fluxes using initial flux guess by FBA\n",
    "        # fit.prepare(n_jobs = 1)\n",
    "        # res = fit.solve(\n",
    "        #     solver = 'slsqp',\n",
    "        #     ini_fluxes = INI_FLUX,\n",
    "        #     fit_measured_fluxes = True,\n",
    "        # )\n",
    "        \n",
    "        # slove the fluxes without reference\n",
    "        fit.prepare(n_jobs = 1)\n",
    "        res = fit.solve(\n",
    "            solver = 'slsqp'\n",
    "        )\n",
    "        results_fit_1.append(res)\n",
    "        obj_fit_1.append(res.opt_objective)\n",
    "\n",
    "    \n",
    "    pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_csv(\n",
    "        result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "    )\n",
    "    \n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "        result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "        result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_csv(\n",
    "        result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_csv(\n",
    "        result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2c3a1-9b8b-4265-b8e6-5367d0c8b574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "results_fit_2 = []\n",
    "obj_fit_2     = []\n",
    "for i in range(1, 11):\n",
    "\n",
    "    # make directory\n",
    "    result_dir = base_dir + str(i)\n",
    "    os.mkdir(result_dir)\n",
    "    \n",
    "    model = ff.Model('wt_10cu')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        \n",
    "        # specify the lableing strategy, use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "\n",
    "        # set bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "        fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('atpm', bounds = [20, 30])\n",
    "        fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "\n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "\n",
    "        # slove the fluxes using initial flux guess by FBA\n",
    "        # fit.prepare(n_jobs = 1)\n",
    "        # res = fit.solve(\n",
    "        #     solver = 'slsqp',\n",
    "        #     ini_fluxes = INI_FLUX,\n",
    "        #     fit_measured_fluxes = True,\n",
    "        # )\n",
    "        \n",
    "        # slove the fluxes without reference\n",
    "        fit.prepare(n_jobs = 1)\n",
    "        res = fit.solve(\n",
    "            solver = 'slsqp'\n",
    "        )\n",
    "        results_fit_2.append(res)\n",
    "        obj_fit_2.append(res.opt_objective)\n",
    "\n",
    "    \n",
    "    pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_csv(\n",
    "        result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "    )\n",
    "    \n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "        result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "        result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_csv(\n",
    "        result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_csv(\n",
    "        result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c528549-90ba-46c8-ac11-d47ed05488da",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fit_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ddc54-a0d1-4391-ba83-2bc020e88091",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fit_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf1471-f885-4389-b573-b1bd12b90f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_1/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "results_fit_ini_1 = []\n",
    "obj_fit_ini_1     = []\n",
    "for i in range(21, 31):\n",
    "\n",
    "    # make directory\n",
    "    result_dir = base_dir + str(i)\n",
    "    os.mkdir(result_dir)\n",
    "    \n",
    "    model = ff.Model('wt_10cu')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        \n",
    "        # specify the lableing strategy, use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "\n",
    "        # set bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "        fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('atpm', bounds = [20, 30])\n",
    "        fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "\n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "\n",
    "\n",
    "        \n",
    "        # slove the fluxes using initial flux guess by FBA\n",
    "        fit.prepare(n_jobs = 1)\n",
    "        res = fit.solve(\n",
    "            solver = 'slsqp',\n",
    "            ini_fluxes = INI_FLUX,\n",
    "            fit_measured_fluxes = True,\n",
    "        )\n",
    "        \n",
    "        # # slove the fluxes without reference\n",
    "        # fit.prepare(n_jobs = 1)\n",
    "        # res = fit.solve(\n",
    "        #     solver = 'slsqp'\n",
    "        # )\n",
    "\n",
    "\n",
    "        \n",
    "        results_fit_ini_1.append(res)\n",
    "        obj_fit_ini_1.append(res.opt_objective)\n",
    "\n",
    "    \n",
    "    pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_csv(\n",
    "        result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "    )\n",
    "    \n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "        result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "        result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_csv(\n",
    "        result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_csv(\n",
    "        result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da5a85-47b5-48ed-aef8-e4139b9812eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "# MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "results_fit_ini_2 = {}\n",
    "obj_fit_ini_2     = {}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(31, 41):\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        model = ff.Model('wt_10cu')\n",
    "        model.read_from_file(MODEL_FILE)\n",
    "        \n",
    "        with model.fitter('ss') as fit:\n",
    "            \n",
    "            # specify the lableing strategy, use this method for every labeled substrate\n",
    "            fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [1, 1]\n",
    "            )\n",
    "    \n",
    "            # set bounds for fluxes\n",
    "            fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "            fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('atpm', bounds = [15, 30])\n",
    "            fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "            \n",
    "            # read measurements\n",
    "            fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "            fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "    \n",
    "    \n",
    "            \n",
    "            # # slove the fluxes using initial flux guess by FBA\n",
    "            # fit.prepare(n_jobs = 1)\n",
    "            # res = fit.solve(\n",
    "            #     solver = 'slsqp',\n",
    "            #     ini_fluxes = INI_FLUX,\n",
    "            #     fit_measured_fluxes = True,\n",
    "            # )\n",
    "    \n",
    "            # slove the fluxes without reference\n",
    "            fit.prepare(n_jobs = 1)\n",
    "            res = fit.solve(\n",
    "                solver = 'slsqp'\n",
    "            )\n",
    "    \n",
    "            \n",
    "        if res.opt_objective < 1000:\n",
    "\n",
    "            # make directory\n",
    "            result_dir = base_dir + str(i)\n",
    "            os.mkdir(result_dir)\n",
    "            \n",
    "            results_fit_ini_2[str(i)] = res\n",
    "            obj_fit_ini_2[str(i)] = res.opt_objective\n",
    "        \n",
    "            net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "            net_flux.to_csv(\n",
    "                base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "            #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            # )\n",
    "            pd.Series(res.opt_total_fluxes).to_csv(\n",
    "                result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # normal probability plot of residuals\n",
    "            res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # compare simulations and measurements\n",
    "            res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "            res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # export the contribution matrix\n",
    "            res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # export the sensitivity matrix\n",
    "            res.estimate_sensitivity(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_sensitivity(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "\n",
    "    except:\n",
    "        print('SVD converge fail: fit number ' + str(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b50445-c7f1-4914-a48d-3e8cbef70cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fit_ini_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9003f0-047e-491a-9f1e-4b9552b96938",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fit_ini_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63dc791-a3d5-43fe-ae24-af16f46ef341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "# MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "results_fit_ini_2 = {}\n",
    "obj_fit_ini_2     = {}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(71, 81):\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        model = ff.Model('wt_10cu')\n",
    "        model.read_from_file(MODEL_FILE)\n",
    "        \n",
    "        with model.fitter('ss') as fit:\n",
    "            \n",
    "            # specify the lableing strategy, use this method for every labeled substrate\n",
    "            fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [1, 1]\n",
    "            )\n",
    "    \n",
    "            # set bounds for fluxes\n",
    "            fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "            fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('atpm', bounds = [2, 6])\n",
    "            fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "            \n",
    "            # read measurements\n",
    "            fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "            fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "    \n",
    "    \n",
    "            \n",
    "            # # slove the fluxes using initial flux guess by FBA\n",
    "            # fit.prepare(n_jobs = 1)\n",
    "            # res = fit.solve(\n",
    "            #     solver = 'slsqp',\n",
    "            #     ini_fluxes = INI_FLUX,\n",
    "            #     fit_measured_fluxes = True,\n",
    "            # )\n",
    "    \n",
    "            # slove the fluxes without reference\n",
    "            fit.prepare(n_jobs = 1)\n",
    "            res = fit.solve(\n",
    "                solver = 'slsqp'\n",
    "            )\n",
    "    \n",
    "            \n",
    "        if res.opt_objective < 1000:\n",
    "\n",
    "            # make directory\n",
    "            result_dir = base_dir + str(i)\n",
    "            os.mkdir(result_dir)\n",
    "            \n",
    "            results_fit_ini_2[str(i)] = res\n",
    "            obj_fit_ini_2[str(i)] = res.opt_objective\n",
    "        \n",
    "            net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "            net_flux.to_csv(\n",
    "                base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "            #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            # )\n",
    "            pd.Series(res.opt_total_fluxes).to_csv(\n",
    "                result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # normal probability plot of residuals\n",
    "            res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # compare simulations and measurements\n",
    "            res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "            res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # export the contribution matrix\n",
    "            res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # export the sensitivity matrix\n",
    "            res.estimate_sensitivity(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_sensitivity(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "\n",
    "    except:\n",
    "        print('SVD converge fail: fit number ' + str(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebadba0-ceb3-4efc-bb81-8e914d3b5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test FBA with ff_rxn_df\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL.xlsx'\n",
    "\n",
    "ff_md = ff.Model('ff_model_test')\n",
    "ff_md.read_from_file(MODEL_FILE)\n",
    "with ff_md.optimizer() as opt:\n",
    "    opt.set_flux_bounds('all', bounds = [-100, 100])\n",
    "    # opt.set_flux_bounds('ch4in', bounds = [13.5, 15])\n",
    "    opt.set_flux_bounds('o2in', bounds = [21.2, 21.2])\n",
    "    opt.set_flux_bounds('atpm', bounds = [25.3, 25.3])\n",
    "    # opt.set_flux_bounds('pyrin', bounds = [0, 2])\n",
    "    # opt.set_flux_bounds('rxn00154_c0', bounds = [0, 1])\n",
    "\n",
    "    # opt.set_flux_bounds('o2in', bounds = [23, 23])\n",
    "\n",
    "    # opt.set_flux_bounds('rxn07847_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn07848_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn37236_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn02480_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn02431_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn07849_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn00371_c0', bounds = [0, 100])\n",
    "    # opt.set_flux_bounds('rxn00248_c0', bounds = [-100, 0])\n",
    "\n",
    "    # opt.set_flux_bounds('rxn00182_c0', bounds = [0, 0])\n",
    "    # opt.set_flux_bounds('rxn00184_c0', bounds = [0, 0])\n",
    "    # opt.set_flux_bounds('atps2', bounds = [0, 1])\n",
    "    # opt.set_flux_bounds('biom', bounds = [0.10, 0.10])\n",
    "    \n",
    "    opt.prepare()\n",
    "    res = opt.optimize(objective = {'biom': 1})\n",
    "    # res = opt.optimize(objective = {'o2in': 1})\n",
    "\n",
    "fluxes_pd_series = pd.Series(\n",
    "    [res.opt_fluxes[rxn] for rxn in ff_md.reactions], name = 'fluxes', index = ff_md.reactions\n",
    ")\n",
    "fluxes_pd_series.to_excel(base_dir + '0_data/WT_FBA_ref_TEST.xlsx')\n",
    "fluxes_pd_series.to_csv(base_dir + '0_data/WT_FBA_ref_TEST.csv')\n",
    "\n",
    "# print('objective:  ',res.opt_objective)\n",
    "print('growth:     ',res.opt_fluxes['biom'])\n",
    "print('methane:    ',res.opt_fluxes['ch4in'])\n",
    "print('oxygen:     ',res.opt_fluxes['o2in'])\n",
    "# print('atpase_1:   ',res.opt_fluxes['atps1'])\n",
    "# print('atpase_2:   ',res.opt_fluxes['atps2'])\n",
    "# print('acetate_out:',res.opt_fluxes['acout'])\n",
    "\n",
    "# print('pyruvate_in:',res.opt_fluxes['pyrin'])\n",
    "# print('citrate_out:',res.opt_fluxes['citout'])\n",
    "# print('succ_out:   ',res.opt_fluxes['succout'])\n",
    "# print('fum_out:    ',res.opt_fluxes['fumout'])\n",
    "\n",
    "# print('formate_out:',res.opt_fluxes['forout'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae87eaf-c4e3-44e6-b15b-7d9afa9f026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL.xlsx'\n",
    "MODEL_FILE       = base_dir + '0_data/ff_rxn_df_test.xlsx'\n",
    "\n",
    "# MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/test_MDVs.xlsx'\n",
    "\n",
    "# MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/test_fluxes.xlsx'\n",
    "\n",
    "\n",
    "# INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "# INI_FLUX         = base_dir + '0_data/estimated_net_fluxes_65_BestFit.xlsx'\n",
    "\n",
    "results_fit_ini_2 = {}\n",
    "obj_fit_ini_2     = {}\n",
    "\n",
    "for i in range(71, 72):\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        model = ff.Model('wt_10cu')\n",
    "        model.read_from_file(MODEL_FILE)\n",
    "        \n",
    "        with model.fitter('ss') as fit:\n",
    "            \n",
    "            # specify the lableing strategy, use this method for every labeled substrate\n",
    "            fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [1, 1]\n",
    "            )\n",
    "    \n",
    "            # # set bounds for fluxes\n",
    "            # fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "            # fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "            # fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "            # fit.set_flux_bounds('atpm', bounds = [15, 30])\n",
    "            # fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "\n",
    "            fit.set_flux_bounds('all', bounds = [-100, 100])\n",
    "            fit.set_flux_bounds('ch4in', bounds = [13, 15])\n",
    "            fit.set_flux_bounds('biom', bounds = [0.07, 0.11])\n",
    "            \n",
    "            # read measurements\n",
    "            fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "            fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "    \n",
    "    \n",
    "            \n",
    "            # # slove the fluxes using initial flux guess by FBA\n",
    "            # fit.prepare(n_jobs = 1)\n",
    "            # res = fit.solve(\n",
    "            #     solver = 'slsqp',\n",
    "            #     ini_fluxes = INI_FLUX,\n",
    "            #     fit_measured_fluxes = True,\n",
    "            # )\n",
    "    \n",
    "            # slove the fluxes without reference\n",
    "            fit.prepare(n_jobs = 1)\n",
    "            res = fit.solve(\n",
    "                solver = 'slsqp'\n",
    "            )\n",
    "    \n",
    "        # print(str(i) + ': ' + str(res.opt_objective))\n",
    "        \n",
    "        # if res.opt_objective < 5000:\n",
    "\n",
    "        # make directory\n",
    "        result_dir = base_dir + str(i)\n",
    "        os.mkdir(result_dir)\n",
    "        \n",
    "        results_fit_ini_2[str(i)] = res\n",
    "        obj_fit_ini_2[str(i)] = res.opt_objective\n",
    "    \n",
    "        net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "        net_flux.to_csv(\n",
    "            base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        )\n",
    "        # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        # )\n",
    "        pd.Series(res.opt_total_fluxes).to_csv(\n",
    "            result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "        )\n",
    "        \n",
    "        # normal probability plot of residuals\n",
    "        res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "        \n",
    "        # compare simulations and measurements\n",
    "        res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "        res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "        \n",
    "        # export the contribution matrix\n",
    "        res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "            result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "            result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        \n",
    "        # export the sensitivity matrix\n",
    "        res.estimate_sensitivity(which = 'net').to_csv(\n",
    "            result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        res.estimate_sensitivity(which = 'total').to_csv(\n",
    "            result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "\n",
    "    except:\n",
    "        print('SVD converge fail: fit number ' + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f660c11-a488-477d-a7a5-70c8c6231467",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_COPY.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "OUT_DIR          = base_dir + 'result_7'\n",
    "\n",
    "# INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "def steady_state_fitting():\n",
    "\n",
    "    wt = ff.Model('OB3b_10copper')\n",
    "    wt.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with wt.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [0.9999, 0.99]\n",
    "            )\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "        \n",
    "        # set upper and lower bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "        # fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('atpm', bounds = [15, 30])\n",
    "        fit.set_flux_bounds('biom', bounds = [0.07, 0.14])\n",
    "\n",
    "        # solve the fluxes\n",
    "        fit.prepare(n_jobs = 3)\n",
    "        while True:\n",
    "            res = fit.solve(solver = 'slsqp')\n",
    "            if res.optimization_successful:\n",
    "                break\n",
    "    \n",
    "    # save the results\n",
    "    pd.Series(res.opt_net_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_net_fluxes.xlsx'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_total_fluxes.xlsx'\n",
    "    )\n",
    "\n",
    "    net_cis = res.estimate_confidence_intervals(\n",
    "        which = 'net', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(net_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/netflux_le_CIs.xlsx'\n",
    "    )\n",
    "    \n",
    "    total_cis = res.estimate_confidence_intervals(\n",
    "        which = 'total', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(total_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/totalflux_le_CIs.xlsx'\n",
    "    )\n",
    "\n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = OUT_DIR)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_contribMat.xlsx'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_contribMat.xlsx'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_senMat.xlsx'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_senMat.xlsx'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003236bb-e91f-4de6-bd31-2cd4c0f761ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "steady_state_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d62c5a-f86b-4f69-8e96-a743b1dd9883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19fc9d-bca0-48f4-b21d-8dffe0514a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c8ba4-63aa-4c1a-9141-5b5b84548882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013dc0e7-fbb8-4dbe-ab4c-35ff6a003efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84455b-ea18-4098-9c9e-4269372d70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL.xlsx'\n",
    "MODEL_FILE       = base_dir + 'ff_rxn_df_test.xlsx'\n",
    "\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "# INI_FLUX         = base_dir + '0_data/estimated_net_fluxes_65_BestFit.xlsx'\n",
    "\n",
    "results_fit_ini_2 = {}\n",
    "obj_fit_ini_2     = {}\n",
    "\n",
    "for i in range(71, 81):\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        model = ff.Model('wt_10cu')\n",
    "        model.read_from_file(MODEL_FILE)\n",
    "        \n",
    "        with model.fitter('ss') as fit:\n",
    "            \n",
    "            # specify the lableing strategy, use this method for every labeled substrate\n",
    "            fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [1, 1]\n",
    "            )\n",
    "    \n",
    "            # set bounds for fluxes\n",
    "            fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "            fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('atpm', bounds = [15, 30])\n",
    "            fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "            \n",
    "            # read measurements\n",
    "            fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "            fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "    \n",
    "    \n",
    "            \n",
    "            # # slove the fluxes using initial flux guess by FBA\n",
    "            # fit.prepare(n_jobs = 1)\n",
    "            # res = fit.solve(\n",
    "            #     solver = 'slsqp',\n",
    "            #     ini_fluxes = INI_FLUX,\n",
    "            #     fit_measured_fluxes = True,\n",
    "            # )\n",
    "    \n",
    "            # slove the fluxes without reference\n",
    "            fit.prepare(n_jobs = 1)\n",
    "            res = fit.solve(\n",
    "                solver = 'slsqp'\n",
    "            )\n",
    "    \n",
    "        # print(str(i) + ': ' + str(res.opt_objective))\n",
    "        \n",
    "        # if res.opt_objective < 5000:\n",
    "\n",
    "        # make directory\n",
    "        result_dir = base_dir + str(i)\n",
    "        os.mkdir(result_dir)\n",
    "        \n",
    "        results_fit_ini_2[str(i)] = res\n",
    "        obj_fit_ini_2[str(i)] = res.opt_objective\n",
    "    \n",
    "        net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "        net_flux.to_csv(\n",
    "            base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        )\n",
    "        # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        # )\n",
    "        pd.Series(res.opt_total_fluxes).to_csv(\n",
    "            result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "        )\n",
    "        \n",
    "        # normal probability plot of residuals\n",
    "        res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "        \n",
    "        # compare simulations and measurements\n",
    "        res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "        res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "        \n",
    "        # export the contribution matrix\n",
    "        res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "            result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "            result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        \n",
    "        # export the sensitivity matrix\n",
    "        res.estimate_sensitivity(which = 'net').to_csv(\n",
    "            result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        res.estimate_sensitivity(which = 'total').to_csv(\n",
    "            result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "\n",
    "    except:\n",
    "        print('SVD converge fail: fit number ' + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ac475-2366-4949-ac3c-63c3bef10461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "# MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "results_fit_ini_2 = {}\n",
    "obj_fit_ini_2     = {}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(71, 131):\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        model = ff.Model('wt_10cu')\n",
    "        model.read_from_file(MODEL_FILE)\n",
    "        \n",
    "        with model.fitter('ss') as fit:\n",
    "            \n",
    "            # specify the lableing strategy, use this method for every labeled substrate\n",
    "            fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [1, 1]\n",
    "            )\n",
    "    \n",
    "            # set bounds for fluxes\n",
    "            fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "            fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('atpm', bounds = [15, 30])\n",
    "            fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "            \n",
    "            # read measurements\n",
    "            fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "            fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "    \n",
    "    \n",
    "            \n",
    "            # # slove the fluxes using initial flux guess by FBA\n",
    "            # fit.prepare(n_jobs = 1)\n",
    "            # res = fit.solve(\n",
    "            #     solver = 'slsqp',\n",
    "            #     ini_fluxes = INI_FLUX,\n",
    "            #     fit_measured_fluxes = True,\n",
    "            # )\n",
    "    \n",
    "            # slove the fluxes without reference\n",
    "            fit.prepare(n_jobs = 1)\n",
    "            res = fit.solve(\n",
    "                solver = 'slsqp'\n",
    "            )\n",
    "    \n",
    "            \n",
    "        if res.opt_objective < 5000:\n",
    "\n",
    "            # make directory\n",
    "            result_dir = base_dir + str(i)\n",
    "            os.mkdir(result_dir)\n",
    "            \n",
    "            results_fit_ini_2[str(i)] = res\n",
    "            obj_fit_ini_2[str(i)] = res.opt_objective\n",
    "        \n",
    "            net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "            net_flux.to_csv(\n",
    "                base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "            #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            # )\n",
    "            pd.Series(res.opt_total_fluxes).to_csv(\n",
    "                result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # normal probability plot of residuals\n",
    "            res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # compare simulations and measurements\n",
    "            res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "            res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # export the contribution matrix\n",
    "            res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # export the sensitivity matrix\n",
    "            res.estimate_sensitivity(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_sensitivity(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "\n",
    "    except:\n",
    "        print('SVD converge fail: fit number ' + str(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030f0eb-213e-4809-adda-1aeeea04eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_3/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "INI_FLUX         = base_dir + '0_data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "results_fit_ini_3 = {}\n",
    "obj_fit_ini_3     = {}\n",
    "\n",
    "for i in range(1, 11):\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        model = ff.Model('wt_10cu')\n",
    "        model.read_from_file(MODEL_FILE)\n",
    "        \n",
    "        with model.fitter('ss') as fit:\n",
    "            \n",
    "            # specify the lableing strategy, use this method for every labeled substrate\n",
    "            fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [1, 1]\n",
    "            )\n",
    "    \n",
    "            # set bounds for fluxes\n",
    "            fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "            fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('ch4in', bounds = [0, 30])\n",
    "            fit.set_flux_bounds('atpm', bounds = [15, 30])\n",
    "            fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "            \n",
    "            # read measurements\n",
    "            fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "            fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "    \n",
    "           \n",
    "            # # slove the fluxes using initial flux guess by FBA\n",
    "            # fit.prepare(n_jobs = 1)\n",
    "            # res = fit.solve(\n",
    "            #     solver = 'slsqp',\n",
    "            #     ini_fluxes = INI_FLUX,\n",
    "            #     fit_measured_fluxes = True,\n",
    "            # )\n",
    "    \n",
    "            # slove the fluxes without reference\n",
    "            fit.prepare(n_jobs = 1)\n",
    "            res = fit.solve(\n",
    "                solver = 'slsqp'\n",
    "            )\n",
    "    \n",
    "        print(str(i) + ': ' + str(res.opt_objective))\n",
    "\n",
    "        # make directory\n",
    "        result_dir = base_dir + str(i)\n",
    "        os.mkdir(result_dir)\n",
    "        \n",
    "        results_fit_ini_3[str(i)] = res\n",
    "        obj_fit_ini_3[str(i)] = res.opt_objective\n",
    "    \n",
    "        net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "        net_flux.to_csv(\n",
    "            base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        )\n",
    "        # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        # )\n",
    "        pd.Series(res.opt_total_fluxes).to_csv(\n",
    "            result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "        )\n",
    "        \n",
    "        # normal probability plot of residuals\n",
    "        res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "        \n",
    "        # compare simulations and measurements\n",
    "        res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "        res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "        \n",
    "        # export the contribution matrix\n",
    "        res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "            result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "            result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        \n",
    "        # export the sensitivity matrix\n",
    "        res.estimate_sensitivity(which = 'net').to_csv(\n",
    "            result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "        )\n",
    "        res.estimate_sensitivity(which = 'total').to_csv(\n",
    "            result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "        # if res.opt_objective < 5000:\n",
    "\n",
    "        #     # make directory\n",
    "        #     result_dir = base_dir + str(i)\n",
    "        #     os.mkdir(result_dir)\n",
    "            \n",
    "        #     results_fit_ini_2[str(i)] = res\n",
    "        #     obj_fit_ini_2[str(i)] = res.opt_objective\n",
    "        \n",
    "        #     net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "        #     net_flux.to_csv(\n",
    "        #         base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        #     )\n",
    "        #     # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        #     #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "        #     # )\n",
    "        #     pd.Series(res.opt_total_fluxes).to_csv(\n",
    "        #         result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "        #     )\n",
    "            \n",
    "        #     # normal probability plot of residuals\n",
    "        #     res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "        #     # compare simulations and measurements\n",
    "        #     res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "        #     res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "        #     # export the contribution matrix\n",
    "        #     res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "        #         result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "        #     )\n",
    "        #     res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "        #         result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "        #     )\n",
    "            \n",
    "        #     # export the sensitivity matrix\n",
    "        #     res.estimate_sensitivity(which = 'net').to_csv(\n",
    "        #         result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "        #     )\n",
    "        #     res.estimate_sensitivity(which = 'total').to_csv(\n",
    "        #         result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "        #     )\n",
    "\n",
    "    except:\n",
    "        print('SVD converge fail: fit number ' + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551d286-bc51-4755-999f-eabac81611ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(41, 44):\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        model = ff.Model('wt_10cu')\n",
    "        model.read_from_file(MODEL_FILE)\n",
    "        \n",
    "        with model.fitter('ss') as fit:\n",
    "            \n",
    "            # specify the lableing strategy, use this method for every labeled substrate\n",
    "            fit.set_labeling_strategy(\n",
    "                'cpd01024.ex', \n",
    "                labeling_pattern = ['0', '1'], \n",
    "                percentage = [0.75, 0.25], \n",
    "                purity = [1, 1]\n",
    "            )\n",
    "    \n",
    "            # set bounds for fluxes\n",
    "            fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "            fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "            fit.set_flux_bounds('atpm', bounds = [2, 6])\n",
    "            fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "            \n",
    "            # read measurements\n",
    "            fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "            fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "    \n",
    "    \n",
    "            \n",
    "            # slove the fluxes using initial flux guess by FBA\n",
    "            fit.prepare(n_jobs = 1)\n",
    "            res = fit.solve(\n",
    "                solver = 'slsqp',\n",
    "                ini_fluxes = INI_FLUX,\n",
    "                fit_measured_fluxes = True,\n",
    "            )\n",
    "    \n",
    "            # # slove the fluxes without reference\n",
    "            # fit.prepare(n_jobs = 1)\n",
    "            # res = fit.solve(\n",
    "            #     solver = 'slsqp'\n",
    "            # )\n",
    "    \n",
    "        print(res.opt_objective)\n",
    "        \n",
    "        if res.opt_objective < 1000:\n",
    "\n",
    "            # make directory\n",
    "            result_dir = base_dir + str(i)\n",
    "            os.mkdir(result_dir)\n",
    "            \n",
    "            results_fit_ini_1[str(i)] = res\n",
    "            obj_fit_ini_1[str(i)] = res.opt_objective\n",
    "        \n",
    "            net_flux = pd.concat([  pd.Series(res.opt_net_fluxes)  ,  pd.Series([res.opt_objective], index = ['opt_objective'])  ])\n",
    "            net_flux.to_csv(\n",
    "                base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            # pd.Series(res.opt_net_fluxes).to_csv(\n",
    "            #     base_dir + '/estimated_net_fluxes_' + str(i) + '.csv'\n",
    "            # )\n",
    "            pd.Series(res.opt_total_fluxes).to_csv(\n",
    "                result_dir + '/estimated_total_fluxes_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # normal probability plot of residuals\n",
    "            res.plot_normal_probability(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # compare simulations and measurements\n",
    "            res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = result_dir)\n",
    "            res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = result_dir)\n",
    "            \n",
    "            # export the contribution matrix\n",
    "            res.estimate_contribution_matrix(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_contribution_matrix(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_contribMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            \n",
    "            # export the sensitivity matrix\n",
    "            res.estimate_sensitivity(which = 'net').to_csv(\n",
    "                result_dir + '/netflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "            res.estimate_sensitivity(which = 'total').to_csv(\n",
    "                result_dir + '/totalflux_senMat_' + str(i) + '.csv'\n",
    "            )\n",
    "\n",
    "    except:\n",
    "        print('SVD converge fail: fit number ' + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8b25f-6d9a-446f-9094-45af7073f4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ca138-2fe8-4d47-b743-fa9709b25f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24843f-7499-46a5-a8b7-f8ccf10bf533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554287fc-5f34-4320-bfcb-248014b54894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb9b0d-a128-4694-b36f-5d0566002379",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.opt_net_fluxes['opt_objective'] = obj_fit_ini_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b3079-76d4-45f6-85ac-ee9159e03be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.Series(res.opt_net_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7aef8-bf2b-43ba-951f-eec507c6c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.append(pd.Series([res.opt_objective], index = ['opt_objective']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffc110-65af-4479-aa66-8c2a41011da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_Dir = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/'\n",
    "\n",
    "MODEL_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Good_Fit_1/Data/WT_10CU_MODEL_TEST.xlsx'\n",
    "\n",
    "# MEASURED_MDVS = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/WT_10CU_MDV.xlsx'\n",
    "MEASURED_MDVS = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Good_Fit_1/Data/WT_10CU_MDV_TEST.xlsx'\n",
    "\n",
    "MEASURED_FLUXES = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Good_Fit_1/Data/WT_10CU_FLUX.xlsx'\n",
    "\n",
    "# INI_FLUX = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/WT_FBA_ref.xlsx'\n",
    "INI_FLUX = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Good_Fit_1/Data/WT_FBA_ref_TEST.xlsx'\n",
    "\n",
    "# OUT_DIR = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Good_Fit_1/'\n",
    "OUT_DIR = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/WT_results/'\n",
    "\n",
    "\n",
    "# estimate fluxes at steady state\n",
    "def wt_model_steady_state_fitting():\n",
    "    \n",
    "    model = ff.Model('wt_10cu')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "        \n",
    "        # set bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-50, 50])\n",
    "        fit.set_flux_bounds('o2in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [10, 30])\n",
    "        fit.set_flux_bounds('atpm', bounds = [20, 30])\n",
    "        fit.set_flux_bounds('biom', bounds = [0.04, 0.2])\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "\n",
    "        # slove the fluxes\n",
    "        # fit.prepare(n_jobs = 1)\n",
    "        # res = fit.solve(\n",
    "        #     solver = 'slsqp',\n",
    "        #     ini_fluxes = INI_FLUX,\n",
    "        #     fit_measured_fluxes = True,\n",
    "        # )\n",
    "        \n",
    "        # slove the fluxes\n",
    "        fit.prepare(n_jobs = 1)\n",
    "        res = fit.solve(\n",
    "            solver = 'slsqp'\n",
    "        )\n",
    "    # print(res.optimization_successful)\n",
    "    \n",
    "    # save the results\n",
    "    # pd.Series(res.opt_net_fluxes).to_excel(\n",
    "    #     OUT_DIR+'/estimated_net_fluxes.xlsx'\n",
    "    # )\n",
    "    pd.Series(res.opt_net_fluxes).to_csv(\n",
    "        OUT_DIR+'/estimated_net_fluxes.csv'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_total_fluxes.xlsx'\n",
    "    )\n",
    "    \n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = OUT_DIR)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_contribMat.xlsx'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_contribMat.xlsx'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_senMat.xlsx'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_senMat.xlsx'\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20428698-055e-4389-a9ed-0b06e11e248f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt_model_steady_state_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2aec5-8563-4cd7-9892-35544b7e6098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1b00f-1422-4438-9130-b2b6287a0ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98266708-e459-4e87-b3ce-81afbd235c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05011ef2-376d-4bb1-94e5-caebaba7ccf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098105b-28ff-4ba0-90e0-66ce2207465b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cadcf-31be-4c3c-ab11-5ad5f23080c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7048ae-c410-4396-ad41-cd90d703dca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78997340-bea3-4563-b242-520d0a867e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa99f38-4714-41fc-be37-cc54ed285088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f91785-fb20-4d8f-bc82-0f860560f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate with confidence intervals\n",
    "def wt_model_steady_state_fitting_CIs():\n",
    "\n",
    "    model = ff.Model('demo')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "        \n",
    "        # set upper and lower bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-100, 100])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [13, 15])\n",
    "        fit.set_flux_bounds('rxn00182_c0', bounds = [0, 0.0001])\n",
    "        fit.set_flux_bounds('rxn00184_c0', bounds = [0, 0.0001])\n",
    "    \n",
    "        fit.set_flux_bounds('biom', bounds = [0.09, 0.11])\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "        \n",
    "        # estimate the confidence intervals\n",
    "        fit.prepare(n_jobs = 3)\n",
    "        res = fit.solve_with_confidence_intervals(\n",
    "            solver = 'slsqp', \n",
    "            n_runs = 100, \n",
    "            n_jobs = 3\n",
    "        )\n",
    "    \n",
    "    # save the CIs\n",
    "    net_cis = res.estimate_confidence_intervals(\n",
    "        which = 'net', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(net_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/netflux_CIs.xlsx'\n",
    "    )\n",
    "\n",
    "    total_cis = res.estimate_confidence_intervals(\n",
    "        which = 'total', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(total_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/totalflux_CIs.xlsx'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     makedirs(OUT_DIR, exist_ok = True)\n",
    "#     toy_model_steady_state_fitting()\n",
    "#     toy_model_steady_state_fitting_CIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07cd6e-ad9d-4c12-a59b-6590b15b352c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c7a19-90e4-43ce-a4ce-5fe0eed30ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f3526-7e29-4dd9-ad57-ba18bc406851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85845c-47eb-4907-bca5-dd1689b6bf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ba33b-1212-4a6b-b766-dce2cc4924dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d844e2-aef9-4353-87a4-649a38f6cf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196bc72-848c-4a08-a0a3-fe7894d396f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffd30f-198b-4697-8970-e694bb355da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes_pd_series = pd.Series(\n",
    "    [res.opt_fluxes[rxn] for rxn in ff_md.reactions], name = 'fluxes', index = ff_md.reactions\n",
    ")\n",
    "\n",
    "fluxes_pd_series.to_csv('ff_fba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65bf07-7a48-44e4-bb98-1b18964fb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('growth:     ',res.opt_fluxes['biom'])\n",
    "print('methane:    ',res.opt_fluxes['ch4in'])\n",
    "print('oxygen:     ',res.opt_fluxes['o2in'])\n",
    "print('atpase_1:   ',res.opt_fluxes['atps1'])\n",
    "print('atpase_2:   ',res.opt_fluxes['atps2'])\n",
    "print('acetate_out:',res.opt_fluxes['acout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df7717-d99e-47e1-9cc8-e498fd4264d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_rxn_df_test.xlsx'\n",
    "FLUXES_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_fba_test.xlsx'\n",
    "\n",
    "ff_md = ff.Model('ff_model_test')\n",
    "ff_md.read_from_file(MODEL_FILE)\n",
    "with ff_md.simulator('ss') as sim:\n",
    "    sim.set_target_EMUs({\n",
    "        'cpd00022': '12',\n",
    "        'cpd00130': '1234',\n",
    "        'cpd00035': '123',\n",
    "        'cpd00036': '1234',\n",
    "        'cpd00054': '123',\n",
    "        'cpd00137': '12345'\n",
    "    })\n",
    "    sim.set_labeling_strategy(\n",
    "        'cpd01024.ex',\n",
    "        labeling_pattern = ['1'],\n",
    "        percentage = [0.25],\n",
    "        purity = [0.998]\n",
    "    )\n",
    "    sim.set_fluxes_from_file(FLUXES_FILE)\n",
    "    sim.prepare(n_jobs = 1)\n",
    "    res = sim.simulate()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d6372-af71-495f-b549-43c38fdcc125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_rxn_df_test.xlsx'\n",
    "FLUXES_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_fba_test.xlsx'\n",
    "\n",
    "ff_md = ff.Model('ff_model_test')\n",
    "ff_md.read_from_file(MODEL_FILE)\n",
    "with ff_md.simulator('ss') as sim:\n",
    "    sim.set_target_EMUs({\n",
    "        'cpd00022': '12',\n",
    "        'cpd00130': '1234',\n",
    "        'cpd00035': '123',\n",
    "        'cpd00036': '1234',\n",
    "        'cpd00054': '123',\n",
    "        'cpd00137': '12345'\n",
    "    })\n",
    "    sim.set_labeling_strategy(\n",
    "        'cpd01024.ex',\n",
    "        labeling_pattern = ['1'],\n",
    "        percentage = [1],\n",
    "        purity = [0.998]\n",
    "    )\n",
    "    sim.set_fluxes_from_file(FLUXES_FILE)\n",
    "    sim.prepare(n_jobs = 1)\n",
    "    res = sim.simulate()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde53192-1ece-44ed-b97f-20978ca76e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_rxn_df_test.xlsx'\n",
    "FLUXES_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_fba_test_2.xlsx'\n",
    "\n",
    "ff_md = ff.Model('ff_model_test')\n",
    "ff_md.read_from_file(MODEL_FILE)\n",
    "with ff_md.simulator('ss') as sim:\n",
    "    sim.set_target_EMUs({\n",
    "        'cpd00022': '12',\n",
    "        'cpd00130': '1234',\n",
    "        'cpd00035': '123',\n",
    "        'cpd00036': '1234',\n",
    "        'cpd00054': '123',\n",
    "        'cpd00137': '12345'\n",
    "    })\n",
    "    sim.set_labeling_strategy(\n",
    "        'cpd01024.ex',\n",
    "        labeling_pattern = ['1'],\n",
    "        percentage = [0.25],\n",
    "        purity = [0.998]\n",
    "    )\n",
    "    sim.set_fluxes_from_file(FLUXES_FILE)\n",
    "    sim.prepare(n_jobs = 1)\n",
    "    res = sim.simulate()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed9ee7-7957-4773-826b-31f9ca90291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_rxn_df_test.xlsx'\n",
    "# MEASURED_MDVS = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_MDVs.xlsx'\n",
    "# MEASURED_FLUXES = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_fluxes.xlsx'\n",
    "# OUT_DIR = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/results_updated_njob3'\n",
    "\n",
    "\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_COPY.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/ff_rxn_df_test.xlsx'\n",
    "\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "# MEASURED_MDVS    = base_dir + '0_data/test_MDVs.xlsx'\n",
    "\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "# MEASURED_FLUXES  = base_dir + '0_data/test_fluxes.xlsx'\n",
    "\n",
    "# OUT_DIR = base_dir + 'results3'\n",
    "\n",
    "\n",
    "# estimate fluxes at steady state\n",
    "def toy_model_steady_state_fitting():\n",
    "    \n",
    "    model = ff.Model('demo')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "        \n",
    "        # set bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-100, 100])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [10, 25])\n",
    "        # fit.set_flux_bounds('rxn00182_c0', bounds = [0, 0])\n",
    "        # fit.set_flux_bounds('rxn00184_c0', bounds = [0, 0])\n",
    "    \n",
    "        fit.set_flux_bounds('biom', bounds = [0.07, 0.14])\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "\n",
    "        # slove the fluxes\n",
    "        fit.prepare(n_jobs = 1)\n",
    "        res = fit.solve(solver = 'slsqp')\n",
    "    \n",
    "    # print(res.optimization_successful)\n",
    "    \n",
    "    # save the results\n",
    "    pd.Series(res.opt_net_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_net_fluxes.xlsx'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_total_fluxes.xlsx'\n",
    "    )\n",
    "    \n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = OUT_DIR)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_contribMat.xlsx'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_contribMat.xlsx'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_senMat.xlsx'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_senMat.xlsx'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390d738-6e54-4da9-a861-84ff2e0522e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/ff_rxn_df_test.xlsx'\n",
    "# MEASURED_MDVS = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_MDVs.xlsx'\n",
    "# MEASURED_FLUXES = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_fluxes.xlsx'\n",
    "# OUT_DIR = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/results_updated_njob3'\n",
    "\n",
    "\n",
    "base_dir         = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/Fit_2/'\n",
    "MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_COPY.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL_TEST.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/WT_10CU_MODEL.xlsx'\n",
    "# MODEL_FILE       = base_dir + '0_data/ff_rxn_df_test.xlsx'\n",
    "\n",
    "MEASURED_MDVS    = base_dir + '0_data/WT_10CU_MDV_TEST.xlsx'\n",
    "# MEASURED_MDVS    = base_dir + '0_data/test_MDVs.xlsx'\n",
    "\n",
    "MEASURED_FLUXES  = base_dir + '0_data/WT_10CU_FLUX_TEST.xlsx'\n",
    "# MEASURED_FLUXES  = base_dir + '0_data/test_fluxes.xlsx'\n",
    "\n",
    "# OUT_DIR = base_dir + 'results3'\n",
    "\n",
    "\n",
    "# estimate fluxes at steady state\n",
    "def toy_model_steady_state_fitting():\n",
    "    \n",
    "    model = ff.Model('demo')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    fit = model.fitter('ss')\n",
    "    # specify the lableing strategy, \n",
    "    # use this method for every labeled substrate\n",
    "    fit.set_labeling_strategy(\n",
    "        'cpd01024.ex', \n",
    "        labeling_pattern = ['0', '1'], \n",
    "        percentage = [0.75, 0.25], \n",
    "        purity = [1, 1]\n",
    "    )\n",
    "    \n",
    "    # set bounds for fluxes\n",
    "    fit.set_flux_bounds('all', bounds = [-100, 100])\n",
    "    fit.set_flux_bounds('ch4in', bounds = [10, 25])\n",
    "    # fit.set_flux_bounds('rxn00182_c0', bounds = [0, 0])\n",
    "    # fit.set_flux_bounds('rxn00184_c0', bounds = [0, 0])\n",
    "\n",
    "    fit.set_flux_bounds('biom', bounds = [0.07, 0.14])\n",
    "    \n",
    "    # read measurements\n",
    "    fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "    fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "\n",
    "    # slove the fluxes\n",
    "    fit.prepare(n_jobs = 1)\n",
    "    res = fit.solve(solver = 'slsqp')\n",
    "\n",
    "    # print(res.optimization_successful)\n",
    "    \n",
    "    # save the results\n",
    "    pd.Series(res.opt_net_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_net_fluxes.xlsx'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_total_fluxes.xlsx'\n",
    "    )\n",
    "    \n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = OUT_DIR)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_contribMat.xlsx'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_contribMat.xlsx'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_senMat.xlsx'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_senMat.xlsx'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62d0cb-c7ba-4b0d-85b0-e4f47c637980",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = base_dir + 'result_6'\n",
    "toy_model_steady_state_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8b3d7-8148-4898-a93f-377611980e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.opt_net_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462365a-b4c9-417a-bc17-2994b5fa5928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087973f-2d9e-4330-b093-0d145c62a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.opt_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096605a3-e4df-4cfb-8b5b-73769799618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model_steady_state_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe4ce8-2b64-4815-af6b-8eba95df958f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae70893-a5eb-4c2d-97c7-7cd7ed15ad47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f3444-c40c-4a51-9c0f-5b918a767c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/13CFLUX_SIMULATION/WT_SIMULATION/WT_10CU_MODEL.xlsx'\n",
    "MEASURED_MDVS = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_MDVs.xlsx'\n",
    "MEASURED_FLUXES = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_fluxes.xlsx'\n",
    "OUT_DIR = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/results_updated_njob3'\n",
    "\n",
    "\n",
    "# estimate fluxes at steady state\n",
    "def toy_model_steady_state_fitting():\n",
    "    \n",
    "    model = ff.Model('demo')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "        \n",
    "        # set bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-100, 100])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [13, 15])\n",
    "        # fit.set_flux_bounds('rxn00182_c0', bounds = [0, 0])\n",
    "        # fit.set_flux_bounds('rxn00184_c0', bounds = [0, 0])\n",
    "    \n",
    "        fit.set_flux_bounds('biom', bounds = [0.07, 0.11])\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "\n",
    "        # slove the fluxes\n",
    "        fit.prepare(n_jobs = 2)\n",
    "        res = fit.solve(solver = 'slsqp')\n",
    "    \n",
    "    # print(res.optimization_successful)\n",
    "    \n",
    "    # save the results\n",
    "    pd.Series(res.opt_net_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_net_fluxes.xlsx'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_total_fluxes.xlsx'\n",
    "    )\n",
    "    \n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = OUT_DIR)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_contribMat.xlsx'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_contribMat.xlsx'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_senMat.xlsx'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_senMat.xlsx'\n",
    "    )\n",
    "\n",
    "\n",
    "# estimate with confidence intervals\n",
    "def toy_model_steady_state_fitting_CIs():\n",
    "\n",
    "    model = ff.Model('demo')\n",
    "    model.read_from_file(MODEL_FILE)\n",
    "    \n",
    "    with model.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024.ex', \n",
    "            labeling_pattern = ['0', '1'], \n",
    "            percentage = [0.75, 0.25], \n",
    "            purity = [1, 1]\n",
    "        )\n",
    "        \n",
    "        # set upper and lower bounds for fluxes\n",
    "        fit.set_flux_bounds('all', bounds = [-100, 100])\n",
    "        fit.set_flux_bounds('ch4in', bounds = [13, 15])\n",
    "        fit.set_flux_bounds('rxn00182_c0', bounds = [0, 0.0001])\n",
    "        fit.set_flux_bounds('rxn00184_c0', bounds = [0, 0.0001])\n",
    "    \n",
    "        fit.set_flux_bounds('biom', bounds = [0.09, 0.11])\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "        \n",
    "        # estimate the confidence intervals\n",
    "        fit.prepare(n_jobs = 2)\n",
    "        res = fit.solve_with_confidence_intervals(\n",
    "            solver = 'slsqp', \n",
    "            n_runs = 100, \n",
    "            n_jobs = 3\n",
    "        )\n",
    "    \n",
    "    # save the CIs\n",
    "    net_cis = res.estimate_confidence_intervals(\n",
    "        which = 'net', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(net_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/netflux_CIs.xlsx'\n",
    "    )\n",
    "\n",
    "    total_cis = res.estimate_confidence_intervals(\n",
    "        which = 'total', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(total_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/totalflux_CIs.xlsx'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     makedirs(OUT_DIR, exist_ok = True)\n",
    "#     toy_model_steady_state_fitting()\n",
    "#     toy_model_steady_state_fitting_CIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb6d8a7-7227-44a6-add1-be38824217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model_steady_state_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbcbd97-9689-431a-9892-5e09b2ae2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_model_steady_state_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84144f41-ccec-41ee-943f-03c17bd563de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toy_model_steady_state_fitting_CIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337dfea-01e5-4762-8f0d-006a8af3230f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arg_syn = ['rxn00192_c0', 'rxn01917_c0', 'rxn02465_c0', 'rxn01637_c0', \n",
    "           'rxn00469_c0', 'rxn01019_c0', 'rxn01434_c0', 'rxn00802_c0']\n",
    "\n",
    "flip_reaction([md.reactions.rxn01637_c0])\n",
    "\n",
    "lump_path_dict = {'arg_synthesis': arg_syn}\n",
    "\n",
    "for name, path in lump_path_dict.items():\n",
    "\n",
    "    path_rxn_list = [md.reactions.get_by_id(rxn) for rxn in path]\n",
    "    \n",
    "    lumped_cpd_coeff_dict = {}\n",
    "    \n",
    "    for rxn in path_rxn_list:\n",
    "        met_list = list(rxn.metabolites.keys())\n",
    "        for met, coeff in rxn.metabolites.items():\n",
    "            if met in list(lumped_cpd_coeff_dict.keys()):\n",
    "                lumped_cpd_coeff_dict[met] += coeff\n",
    "            else:\n",
    "                lumped_cpd_coeff_dict[met] = coeff\n",
    "\n",
    "    del_cpd = [cpd for cpd, coeff in lumped_cpd_coeff_dict.items() if coeff == 0]\n",
    "    for cpd in del_cpd:\n",
    "        lumped_cpd_coeff_dict.pop(cpd, None)\n",
    "    \n",
    "    lumped_rxn = cobra.Reaction(name)\n",
    "    lumped_rxn.name = name\n",
    "    lumped_rxn.bounds = (0, 1000)\n",
    "    lumped_rxn.add_metabolites(lumped_cpd_coeff_dict)\n",
    "    md.add_reactions([lumped_rxn])\n",
    "\n",
    "md.reactions.arg_synthesis\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1bb8c-8bc8-48dc-8912-1ba5f8e7d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.metabolites.cpd00023_c0.formula_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b98abb-5970-4736-899f-3d48fb2b8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.reactions.rxn00786_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1d302-e75a-401c-9528-528aa5feec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.reactions.rxn00182_c0.metabolites.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5725ac-ac63-47e6-bf17-27fc8ed634a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "test.append(md.metabolites.cpd00001_c0)\n",
    "test.append(md.metabolites.cpd00002_c0)\n",
    "test.append(md.metabolites.cpd00003_c0)\n",
    "test.append(md.metabolites.cpd00004_c0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1569c-21d2-4cdd-8845-d598339b1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = md.metabolites.cpd00008_c0\n",
    "tm in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6c67f-e893-4203-8149-422629e3bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "met = md.metabolites.cpd00087_c0\n",
    "met_formula = met.formula\n",
    "carbon_label = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "met_unpack = [s for s in met_formula]\n",
    "met_re = re.split('(\\d+)',met_formula)\n",
    "\n",
    "try:\n",
    "    c = met_unpack.index('C') + 1\n",
    "except:\n",
    "    c = 0\n",
    "print(c)\n",
    "if c != 0: \n",
    "    try:\n",
    "        c_num_ind = met_re.index('C')+1\n",
    "        c_num = int(met_re[c_num_ind])\n",
    "    except:\n",
    "        c_num = 1\n",
    "else:\n",
    "    c_num = 0 \n",
    "print(c_num)\n",
    "if c_num > 10:\n",
    "    c_num = 0\n",
    "\n",
    "print(c_num)\n",
    "\n",
    "\n",
    "if c_num !=0:\n",
    "    met_id = met.id[0:-3]+'('+carbon_label[0:c_num]+')'\n",
    "else:\n",
    "    met_id = met.id[0:-3]\n",
    "\n",
    "print(met_id)\n",
    "print(len(met.formula))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8094f2c-0d19-4701-a1fb-0ac6616bd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_carbon_list = ['methanopterin', 'h4mpt', 'methanofuran', 'tetrahydrofolate']\n",
    "\n",
    "if '_c0' in md.metabolites.cpd00087_c0.name:\n",
    "    string = md.metabolites.cpd00087_c0.name[:-3]\n",
    "elif '_e0' in md.metabolites.cpd00087_c0.name:\n",
    "    string = md.metabolites.cpd00087_c0.name[:-3]\n",
    "else:\n",
    "    string = md.metabolites.cpd00087_c0.name\n",
    "\n",
    "if any(substring in string.lower() for substring in substring_list):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99a33f-1bf6-4056-85e9-5b8f705cf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '_e0' or '_c0' in md.metabolites.cpd01024_c0.name:\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76d174-4bcd-4f89-91f1-8f85e8c3a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_e0' or '_c0' in md.metabolites.cpd01024_c0.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747391f5-6705-4f77-9e95-c34b6761175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for met, coeff in md.reactions.get_by_id(t1).metabolites.items():\n",
    "    a.append(str(abs(coeff))+' '+met.id)\n",
    "    \n",
    "a = ' + '.join(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80788c-49ff-4763-bee7-07af7eba1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for met, coeff in md.reactions.get_by_id(t1).metabolites.items():\n",
    "    if coeff == -1:\n",
    "        print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787c859-6da8-47d9-bf85-1ca526d6b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = md.reactions.get_by_id('rxn07847_c0')\n",
    "for met, coeff in t1.metabolites.items():\n",
    "    print(met.formula, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf74db9-d334-4823-8da7-b3daad812b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = md.metabolites.get_by_id('cpd00054_c0')\n",
    "m1.formula\n",
    "for i in m1.formula:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1ed71-bbec-4697-812c-9eb9571af0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a list of ff Reactions\n",
    "\n",
    "ff_md = ff.Model('sMMO_ff_model')\n",
    "rxn_list = []\n",
    "\n",
    "for rxn in md.reactions:\n",
    "\n",
    "    if rxn.lower_bound * rxn.upper_bound < 0:\n",
    "        ff_rxn = ff.Reaction(id=rxn.id, reversible = True)\n",
    "    else:\n",
    "        ff_rxn = ff.Reaction(id=rxn.id, reversible = False)\n",
    "\n",
    "\n",
    "    for met,coeff in rxn.metabolites.items():\n",
    "        if coeff < 0:\n",
    "            ff_rxn.add_substrates(substrates = met_dict[met], stoichiometry = abs(coeff))\n",
    "        elif coeff > 0:\n",
    "            ff_rxn.add_products(products= met_dict[met], stoichiometry = abs(coeff))\n",
    "\n",
    "    rxn_list.append(ff_rxn)\n",
    "    ff_md.add_reactions(reactions=ff_rxn)\n",
    "    # print(ff_rxn)\n",
    "\n",
    "### Five metabolites have no reactions:\n",
    "### cpd00074_c0, cpd00649_c0, cpd00792_c0, cpd11609_c0, cpd11610_c0\n",
    "print(len(md.metabolites), ff_md.n_metabolites)\n",
    "print(len(md.reactions), ff_md.n_reactions)\n",
    "\n",
    "# for met in md.metabolites:\n",
    "#     if met.id not in ff_md.metabolites:\n",
    "#         print(met.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eaf59c-6f39-4eec-b33b-7857ff1298d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ff_md.optimizer() as opt:\n",
    "\n",
    "    for rxn in list(ff_md.reactions_info.keys()):\n",
    "        rxn_lb = md.reactions.get_by_id(rxn).lower_bound\n",
    "        rxn_ub = md.reactions.get_by_id(rxn).upper_bound\n",
    "        opt.set_flux_bounds(fluxid = rxn, bounds = [rxn_lb, rxn_ub])\n",
    "    # opt.prepare()\n",
    "    res = opt.optimize(objective = {'bio1_biomass': 1}, direction='max')\n",
    "\n",
    "print('objective:', res.opt_objective)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895bb7f9-e999-4726-acb9-eea4061efb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('objective:', res.opt_objective)\n",
    "print(res.opt_fluxes['EX_cpd00007_e0'])\n",
    "print(res.opt_fluxes['EX_cpd01024_e0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c9349-0d80-4a19-9dae-e970cb6c461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ff_md.reactions_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0c1bc-e218-416f-8a81-ffad5e28c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = 'freeflux/models/toy/reactions.tsv' \n",
    "MEASURED_MDVS = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_MDVs.xlsx'\n",
    "MEASURED_FLUXES = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/test_fluxes.xlsx'\n",
    "OUT_DIR = '/Users/junwon/Library/CloudStorage/OneDrive-Umich/GEM/MFA13C/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440c93f-a95c-4773-adf0-751c6a2fe83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_steady_state_fitting():\n",
    "\n",
    "    # ecoli = Model('ecoli')\n",
    "    # ecoli.read_from_file(MODEL_FILE)\n",
    "\n",
    "    ecoli = ff_md\n",
    "    \n",
    "    with ecoli.fitter('ss') as fit:\n",
    "        # specify the lableing strategy, \n",
    "        # use this method for every labeled substrate\n",
    "        fit.set_labeling_strategy(\n",
    "            'cpd01024_e0', \n",
    "            labeling_pattern = ['1'], \n",
    "            percentage = [1], \n",
    "            purity = [0.99]\n",
    "        )\n",
    "        \n",
    "        # read measurements\n",
    "        fit.set_measured_MDVs_from_file(MEASURED_MDVS)\n",
    "        fit.set_measured_fluxes_from_file(MEASURED_FLUXES)\n",
    "        \n",
    "        # # set upper and lower bounds for fluxes\n",
    "        # fit.set_flux_bounds('all', bounds = [-100, 100]) \n",
    "\n",
    "        # solve the fluxes\n",
    "        fit.prepare(n_jobs = 3)\n",
    "        while True:\n",
    "            res = fit.solve(solver = 'ralg')\n",
    "            if res.optimization_successful:\n",
    "                break\n",
    "    \n",
    "    # save the results\n",
    "    pd.Series(res.opt_net_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_net_fluxes.xlsx'\n",
    "    )\n",
    "    pd.Series(res.opt_total_fluxes).to_excel(\n",
    "        OUT_DIR+'/estimated_total_fluxes.xlsx'\n",
    "    )\n",
    "\n",
    "    net_cis = res.estimate_confidence_intervals(\n",
    "        which = 'net', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(net_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/netflux_le_CIs.xlsx'\n",
    "    )\n",
    "    \n",
    "    total_cis = res.estimate_confidence_intervals(\n",
    "        which = 'total', \n",
    "        confidence_level = 0.95\n",
    "    )\n",
    "    pd.DataFrame(total_cis, index = ['LB', 'UB']).T.to_excel(\n",
    "        OUT_DIR+'/totalflux_le_CIs.xlsx'\n",
    "    )\n",
    "\n",
    "    # normal probability plot of residuals\n",
    "    res.plot_normal_probability(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # compare simulations and measurements\n",
    "    res.plot_simulated_vs_measured_MDVs(show_fig = False, output_dir = OUT_DIR)\n",
    "    res.plot_simulated_vs_measured_fluxes(show_fig = False, output_dir = OUT_DIR)\n",
    "    \n",
    "    # export the contribution matrix\n",
    "    res.estimate_contribution_matrix(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_contribMat.xlsx'\n",
    "    )\n",
    "    res.estimate_contribution_matrix(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_contribMat.xlsx'\n",
    "    )\n",
    "    \n",
    "    # export the sensitivity matrix\n",
    "    res.estimate_sensitivity(which = 'net').to_excel(\n",
    "        OUT_DIR+'/netflux_senMat.xlsx'\n",
    "    )\n",
    "    res.estimate_sensitivity(which = 'total').to_excel(\n",
    "        OUT_DIR+'/totalflux_senMat.xlsx'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1bdc2-f64b-4c8d-b1f5-487a30cc6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steady_state_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6315c4-1453-447a-b82d-f45eaa0983fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11432bb1-e41d-417b-8faf-6bb24b366b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168592f-e0d3-4144-97ea-d11a51d61f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn = md.reactions.get_by_id('EX_cpd00007_e0')\n",
    "\n",
    "if rxn.lower_bound * rxn.upper_bound < 0:\n",
    "    ff_rxn = ff.Reaction(id=rxn.id, reversible = True)\n",
    "else:\n",
    "    ff_rxn = ff.Reaction(id=rxn.id, reversible = False)\n",
    "\n",
    "\n",
    "for met,coeff in rxn.metabolites.items():\n",
    "    if coeff < 0:\n",
    "        ff_rxn.add_substrates(substrates = met_dict[met], stoichiometry = abs(coeff))\n",
    "    elif coeff > 0:\n",
    "        ff_rxn.add_products(products= met_dict[met], stoichiometry = abs(coeff))\n",
    "\n",
    "print(ff_rxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872d47f-b57e-4397-a19c-9dbe7c3835a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md.reactions.EX_cpd00007_e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5ceda-f19e-449d-bc1b-2d84df39e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.reactions.rxn04996_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103778f8-adf5-4215-8b67-8ac8a78cf0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f1497-0e3a-48bf-881c-d48433d75d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.metabolites.cpd00001_e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80287a01-96ed-4dc4-baea-de42709633a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.reactions.EX_cpd00001_e0.summary(solution = md_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fbc49-9ea1-4094-9546-203e9d7f2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.objective = 'bio1_biomass'\n",
    "md_sol = md.optimize()\n",
    "md.summary(md_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8bd236-807b-41ce-a74a-1151620afbf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md.metabolites.cpd00649_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445eecff-82a8-4b88-8192-754ed16d3bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fd628-f038-430f-95e6-ea38bafd11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in md.reactions.rxn00224_c0.metabolites.items():\n",
    "    if a in met_dict.keys():\n",
    "        print(met_dict[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f8a5e-dd69-4e90-bb28-19f1548220ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in md.reactions.rxn00224_c0.metabolites.items():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a2f3e-ad73-4f5a-8f98-25a538d1a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "a in met_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a914e-e2a6-4d3d-8163-12f4776a882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(met_dict.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
